{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LANGCHAIN_TRACING_V2=\"true\"\n",
    "!export LANGCHAIN_API_KEY=\"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\"\n",
    "!OPENAI_API_KEY="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m docs \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m      8\u001b[0m documents \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(\n\u001b[1;32m      9\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m\n\u001b[1;32m     10\u001b[0m )\u001b[38;5;241m.\u001b[39msplit_documents(docs)\n\u001b[0;32m---> 11\u001b[0m vector \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mfrom_documents(documents, \u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     12\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vector\u001b[38;5;241m.\u001b[39mas_retriever()\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/llava/lib/python3.10/site-packages/langchain_openai/embeddings/base.py:338\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.validate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mClient(proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy)\n\u001b[1;32m    337\u001b[0m     sync_specific \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client}\n\u001b[0;32m--> 338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msync_specific\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39membeddings  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_async_client:\n",
      "File \u001b[0;32m~/anaconda3/envs/llava/lib/python3.10/site-packages/openai/_client.py:105\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    103\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m     )\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ").split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#huggingface 加速"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 17 files:   0%|                                 | 0/17 [00:00<?, ?it/s]Downloading 'original/consolidated.00.pth' to '/root/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B-Instruct/blobs/be52262c9289304f3e8240e0749bf257bc04264405a86cd4de38efb9068724ee.incomplete' (resume from 8294236160/16060617592)\n",
      "/root/miniconda3/envs/llama/lib/python3.13/site-packages/huggingface_hub/file_download.py:653: UserWarning: Not enough free disk space to download the file. The expected file size is: 16060.62 MB. The target location /root/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B-Instruct/blobs only has 0.87 MB free disk space.\n",
      "  warnings.warn(\n",
      "\n",
      "consolidated.00.pth:  52%|████████████▉            | 8.29G/16.1G [00:00<?, ?B/s]\u001b[A\n",
      "consolidated.00.pth:  52%|████████▊        | 8.30G/16.1G [00:02<34:02, 3.80MB/s]\u001b[A\n",
      "Fetching 17 files:  65%|███████████████▌        | 11/17 [00:04<00:02,  2.24it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/root/miniconda3/envs/llama/bin/huggingface-cli\"\u001b[0m, line \u001b[35m8\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    sys.exit(\u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m)\n",
      "             \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/root/miniconda3/envs/llama/lib/python3.13/site-packages/huggingface_hub/commands/huggingface_cli.py\"\u001b[0m, line \u001b[35m57\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    \u001b[31mservice.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/root/miniconda3/envs/llama/lib/python3.13/site-packages/huggingface_hub/commands/download.py\"\u001b[0m, line \u001b[35m153\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    print(\u001b[31mself._download\u001b[0m\u001b[1;31m()\u001b[0m)  # Print path to downloaded files\n",
      "          \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/root/miniconda3/envs/llama/lib/python3.13/site-packages/huggingface_hub/commands/download.py\"\u001b[0m, line \u001b[35m187\u001b[0m, in \u001b[35m_download\u001b[0m\n",
      "    return snapshot_download(\n",
      "        repo_id=self.repo_id,\n",
      "    ...<10 lines>...\n",
      "        max_workers=self.max_workers,\n",
      "    )\n",
      "  File \u001b[35m\"/root/miniconda3/envs/llama/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py\"\u001b[0m, line \u001b[35m114\u001b[0m, in \u001b[35m_inner_fn\u001b[0m\n",
      "    return fn(*args, **kwargs)\n",
      "  File \u001b[35m\"/root/miniconda3/envs/llama/lib/python3.13/site-packages/huggingface_hub/_snapshot_download.py\"\u001b[0m, line \u001b[35m293\u001b[0m, in \u001b[35msnapshot_download\u001b[0m\n",
      "    \u001b[31mthread_map\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31m_inner_hf_hub_download,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    ...<4 lines>...\n",
      "        \u001b[1;31mtqdm_class=tqdm_class or hf_tqdm,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/root/miniconda3/envs/llama/lib/python3.13/site-packages/tqdm/contrib/concurrent.py\"\u001b[0m, line \u001b[35m69\u001b[0m, in \u001b[35mthread_map\u001b[0m\n",
      "    return _executor_map(ThreadPoolExecutor, fn, *iterables, **tqdm_kwargs)\n",
      "  File \u001b[35m\"/root/miniconda3/envs/llama/lib/python3.13/site-packages/tqdm/contrib/concurrent.py\"\u001b[0m, line \u001b[35m51\u001b[0m, in \u001b[35m_executor_map\u001b[0m\n",
      "    return list(tqdm_class(ex.map(fn, *iterables, chunksize=chunksize), **kwargs))\n",
      "  File \u001b[35m\"/root/miniconda3/envs/llama/lib/python3.13/site-packages/tqdm/std.py\"\u001b[0m, line \u001b[35m1181\u001b[0m, in \u001b[35m__iter__\u001b[0m\n",
      "    for obj in \u001b[1;31miterable\u001b[0m:\n",
      "               \u001b[1;31m^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/root/miniconda3/envs/llama/lib/python3.13/concurrent/futures/_base.py\"\u001b[0m, line \u001b[35m619\u001b[0m, in \u001b[35mresult_iterator\u001b[0m\n",
      "    yield \u001b[31m_result_or_cancel\u001b[0m\u001b[1;31m(fs.pop())\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/root/miniconda3/envs/llama/lib/python3.13/concurrent/futures/_base.py\"\u001b[0m, line \u001b[35m317\u001b[0m, in \u001b[35m_result_or_cancel\u001b[0m\n",
      "    return \u001b[31mfut.result\u001b[0m\u001b[1;31m(timeout)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/root/miniconda3/envs/llama/lib/python3.13/concurrent/futures/_base.py\"\u001b[0m, line \u001b[35m456\u001b[0m, in \u001b[35mresult\u001b[0m\n",
      "    return \u001b[31mself.__get_result\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/root/miniconda3/envs/llama/lib/python3.13/concurrent/futures/_base.py\"\u001b[0m, line \u001b[35m401\u001b[0m, in \u001b[35m__get_result\u001b[0m\n",
      "    raise self._exception\n",
      "  File \u001b[35m\"/root/miniconda3/envs/llama/lib/python3.13/concurrent/futures/thread.py\"\u001b[0m, line \u001b[35m59\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \u001b[35m\"/root/miniconda3/envs/llama/lib/python3.13/site-packages/huggingface_hub/_snapshot_download.py\"\u001b[0m, line \u001b[35m267\u001b[0m, in \u001b[35m_inner_hf_hub_download\u001b[0m\n",
      "    return hf_hub_download(\n",
      "        repo_id,\n",
      "    ...<15 lines>...\n",
      "        headers=headers,\n",
      "    )\n",
      "  File \u001b[35m\"/root/miniconda3/envs/llama/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py\"\u001b[0m, line \u001b[35m114\u001b[0m, in \u001b[35m_inner_fn\u001b[0m\n",
      "    return fn(*args, **kwargs)\n",
      "  File \u001b[35m\"/root/miniconda3/envs/llama/lib/python3.13/site-packages/huggingface_hub/file_download.py\"\u001b[0m, line \u001b[35m862\u001b[0m, in \u001b[35mhf_hub_download\u001b[0m\n",
      "    return _hf_hub_download_to_cache_dir(\n",
      "        # Destination\n",
      "    ...<14 lines>...\n",
      "        force_download=force_download,\n",
      "    )\n",
      "  File \u001b[35m\"/root/miniconda3/envs/llama/lib/python3.13/site-packages/huggingface_hub/file_download.py\"\u001b[0m, line \u001b[35m1011\u001b[0m, in \u001b[35m_hf_hub_download_to_cache_dir\u001b[0m\n",
      "    \u001b[31m_download_to_tmp_and_move\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mincomplete_path=Path(blob_path + \".incomplete\"),\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    ...<6 lines>...\n",
      "        \u001b[1;31mforce_download=force_download,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/root/miniconda3/envs/llama/lib/python3.13/site-packages/huggingface_hub/file_download.py\"\u001b[0m, line \u001b[35m1545\u001b[0m, in \u001b[35m_download_to_tmp_and_move\u001b[0m\n",
      "    \u001b[31mhttp_get\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31murl_to_download,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    ...<4 lines>...\n",
      "        \u001b[1;31mexpected_size=expected_size,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/root/miniconda3/envs/llama/lib/python3.13/site-packages/huggingface_hub/file_download.py\"\u001b[0m, line \u001b[35m457\u001b[0m, in \u001b[35mhttp_get\u001b[0m\n",
      "    \u001b[31mtemp_file.write\u001b[0m\u001b[1;31m(chunk)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^\u001b[0m\n",
      "\u001b[1;35mOSError\u001b[0m: \u001b[35m[Errno 28] No space left on device\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !export HF_HOME='/root/autodl-tmp/cache/'\n",
    "!huggingface-cli download meta-llama/Meta-Llama-3-8B-Instruct\n",
    "# /root/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(\"/usr/bin/shutdown\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
